<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
    <head>
        <title>Hadoop : Installing and Configuring DataLoader</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body>
        <div id="page">
            <div id="main">
                <div id="main-header" class="pageSectionHeader">
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Hadoop : Installing and Configuring DataLoader
                        </span>
                    </h1>

                    <div class="page-metadata">
                        <p>This page last changed on Sep 18, 2013 by <font color="#0050B2">beckmj</font>.</p>
                    </div>
                </div>

                <div id="content" class="view">
                    <div id="main-content" class="wiki-content group">
                    <p>DataLoader can manage a dynamic pool of loader machines for fast ingestion of big data. DataLoader works with both Hadoop 1.x (MR1) and Hadoop 2.x (Yarn) and can leverage them as the resource manager and job scheduler.</p><p><br /><strong>Note:</strong> A properly-configured Hadoop cluster is required, and HDFS, MapReduce, and Zookeeper must be available for DataLoader to use. For Hadoop/Zookeeper deployment instructions using the Pivotal HD distribution, refer to the Pivotal HD Installation and Administrator Guide.</p><h1 id="InstallingandConfiguringDataLoader-PackagesandInstallers">Packages and Installers</h1><p>DataLoader is distributed as either RPM packages, or as a binary distribution. The installation procedures are similar. Use the installation procedure that is specific to your distribution. Binary distribution installation can be found in the section: <em>DataLoader Binary Installatiion</em>.</p><h2 id="InstallingandConfiguringDataLoader-RPMpackages:">RPM packages:</h2><p>DataLoader uses two RPM packages that are deployed to the Client and Master, nodes, which can be the same. No worker installation is needed; required files are put in Hadoop DistributedCache for use at runtime.</p><h3 id="InstallingandConfiguringDataLoader-RPMPackagesandDeployment:">RPM Packages and Deployment:</h3><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Package Name</p></td><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Description</p></td><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Deployment Nodes</p></td></tr><tr><td class="confluenceTd"><p>dataloader-cli-2.0.3-nn.x86_64.rpm</p></td><td class="confluenceTd"><p>dataloader-cli-2.0.3-nn.x86_64.rpm provides essential files to setup dataloader client.</p></td><td class="confluenceTd"><p>Client node</p></td></tr><tr><td class="confluenceTd"><p>dataloader-service-2.0.3-nn.x86_64.rpm</p></td><td class="confluenceTd"><p>dataloader-service-2.0.3-nn pr.x86_64.rpmovides essential files to setup dataloader master.</p></td><td class="confluenceTd"><p>Master node</p></td></tr></tbody></table></div><p><strong>Note:</strong> The nn in Package Name is the RPM build number.</p><h2 id="InstallingandConfiguringDataLoader-InstallerScripts">Installer Scripts</h2><ul><li>install_dl.sh</li><li>dl-cluster.conf.template</li></ul><h1 id="InstallingandConfiguringDataLoader-Prerequisites">Prerequisites</h1><h1 id="InstallingandConfiguringDataLoader-InstallationofUserAccount"><span style="font-size: 20.0px;line-height: 1.5;">Installation of User Account</span></h1><p>In most customer environments, root account password and information is strictly controlled. To install DataLoader without using root account, use the process detailed below.</p><h3 id="InstallingandConfiguringDataLoader-CreateanInstallationUserAccount">Create an Installation User Account</h3><p> </p><ol><li>Create a dladmin account on the machines where you will install DataLoader service and client. This dladmin account will be used as a system administrator account for installing DataLoader.</li><li>After the dladmin has been created, give it sudo permissions.</li></ol><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"># vi /etc/sudoers</td></tr></tbody></table></div><p style="margin-left: 30.0px;">This will take you to a text editor with an /etc/sudoers file already opened. Add the following line:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">dladmin ALL=(ALL) NOPASSWD: ALL</td></tr></tbody></table></div><p style="margin-left: 30.0px;">and save the file.</p><h2 id="InstallingandConfiguringDataLoader-PivotalHDandZookeeperClusterInstallation">Pivotal HD and Zookeeper Cluster Installation</h2><p>To install Pivotal HD and the Zookeeper cluster, refer to the Pivotal HD Enterprise Installation and Administrator Guide for deployment instructions.<br />Make sure you include the following in your HDFS configuration.</p><p><br />For HDFS 1.x and HDFS 2.x:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>&lt;configuration&gt;<br />&lt;property&gt;<br />&lt;name&gt;dfs.support.append&lt;/name&gt;<br />&lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;/configuration&gt;</p></td></tr></tbody></table></div><h3 id="InstallingandConfiguringDataLoader-InstalltheJDK"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Install the JDK</span></h3><p>Install the JDK: Download and install the Oracle JDK1.6 (Java SE6 or JDK 6) from:</p><p><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" class="external-link" rel="nofollow">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br />(<a href="http://www.oracle.com/technetwork/java/archive-139210.html" class="external-link" rel="nofollow">http://www.oracle.com/technetwork/java/archive-139210.html</a>)</p><p><span style="line-height: 1.4285715;">After installing JDK, set the JAVA_HOME environment variable referring to where you installed JDK. On a typical Linux installation with Oracle JDK 1.6, the value of this variable should be /usr/java/default/.</span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">export JAVA_HOME=/usr/java/default/</td></tr></tbody></table></div><p>Add $JAVA_HOME/bin into your PATH environment variable. On a Linux platform with bash shell, add the following lines into the file ~/.bashrc:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">export PATH=$JAVA_HOME/bin:$PATH</td></tr></tbody></table></div><h2 id="InstallingandConfiguringDataLoader-DownloadandextracttheDataLoaderfiles">Download and extract the DataLoader files</h2><p><span style="line-height: 1.4285715;">Download and copy the PHDTools stack to /home/dladmin/ on the host where you want to install DataLoader. Make sure the Tarball has read permission for the user 'dladmin'.</span></p><p><span style="line-height: 1.4285715;"> </span>Extract the tarball:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>[root@hdp2-w17 dladmin]# chown <a href="http://dladmindladmin" class="external-link" rel="nofollow">dladmin:dladmin</a> PHDTools-1.0.1-xx.tar.gz<br />[root@hdp2-w17 dladmin]# ls -lrt PHDTools-1.0.1-xx.tar.gz<br />-rw-r--r-- 1 dladmin dladmin 246080597 Jun 24 11:23 PHDTools-1.0.1-xx.tar.gz<br />[root@hdp2-w17 dladmin]# sudo su - dladmin<br />[dladmin@hdp2-w17 ~]$ tar xzvf PHDTools-1.0.1-xx.tar.gz<br />[dladmin@hdp2-w17 ~]$ ls -lrt PHDTools-1.0.1-xx<br />total 12<br />drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:32 uss<br />drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:32 dataloader<br />drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:33 spring-data-hadoop<br />[dladmin@hdp2-w17 ~]$ cd PHDTools-1.0.1-xx/dataloader/rpm/<br />[dladmin@hdp2-w17 rpm]$ ls -lrt<br />total 213224<br />-rw-r--r-- 1 dladmin dladmin 199662368 Jun 24 11:32 dataloader-service-2.0.3-35.x86_64.rpm<br />-rw-r--r-- 1 dladmin dladmin 18647092 Jun 24 11:32 dataloader-cli-2.0.3-35.x86_64.rpm<br />-r-xr-xr-x 1 dladmin dladmin 5251 Jun 24 11:33 install_dl.sh<br />-r--r--r-- 1 dladmin dladmin 167 Jun 24 11:33 dl-cluster.conf.template<br />-rw-rw-r-- 1 dladmin dladmin 69 Jun 24 11:33 dataloader-cli-2.0.3-35.x86_64.rpm.md5<br />-rw-rw-r-- 1 dladmin dladmin 48 Jun 24 11:33 install_dl.sh.md5<br />-rw-rw-r-- 1 dladmin dladmin 59 Jun 24 11:33 dl-cluster.conf.template.md5<br />-rw-rw-r-- 1 dladmin dladmin 73 Jun 24 11:33 dataloader-service-2.0.3-35.x86_64.rpm.md5</p></td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> Note: xx in the package name is the package build number.</span></p><h1 id="InstallingandConfiguringDataLoader-InstallDataLoader"><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Install DataLoader</span></h1><p>Run following commands as user &quot;dladmin&quot; or any user that has root privileges:</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -i
</pre>
</div></div><p><span style="line-height: 1.4285715;">DataLoader service and the CLI tool will be installed at the default location /usr/local/gphd/dataloader-2.0.3/.</span></p><p>After installation, DataLoader can be started in pseudo distributed mode without any further configuration.</p><p><span style="line-height: 1.4285715;"> </span></p><p> </p><p><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Uninstall DataLoader</span></p><p><span style="line-height: 1.4285715;">There are two uninstall options. </span><span style="line-height: 1.4285715;">One option preserves customer data, and the other </span><span style="line-height: 1.4285715;">uninstalls both DataLoader and customer data.</span></p><p>To uninstall DataLoader but preserve customer data, use the command:</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -u
</pre>
</div></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">To uninstall DataLoader and remove both binary and customer data including configuration data, enter the command:</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -u -c
</pre>
</div></div><p><span style="line-height: 1.4285715;"> </span><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configuring DataLoader</span></p><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">Modify the file dataloader-env.sh to reflect your Pivotal HD and Zookeeper cluster configuration. Either host names or their IP addresses can be used. This should be done as root (enter command proceeded by sudo.)</span></p><p>The file is located in /usr/local/gphd/dataloader-2.0.3/conf.</p><p>For pseudo mode, edit the file in /usr/local/gphd/dataloader-2.0.3/conf/pseudo/</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">vi /usr/local/gphd/dataloader-2.0.0/conf/dataloader-env.sh
</pre>
</div></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">The following table shows the basic parameters that must be modified to run DataLoader in distributed mode:</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Parameter</p></th><th class="confluenceTh"><p>Explanation</p></th><th class="confluenceTh"><p>Default value</p></th><th class="confluenceTh"><p>Options</p></th></tr><tr><td colspan="1" class="confluenceTd"><p>DATALOADER_START_MODE</p></td><td colspan="1" class="confluenceTd"><p>This parameter controls the start mode of the DataLoader. Change this parameter if you want to start DataLoader in distributed mode;<br />Note: If you wish to start DataLoader in pseudo distributed mode, please do not change the parameters.</p></td><td colspan="1" class="confluenceTd"> pseudo</td><td colspan="1" class="confluenceTd"> pseudo, distributed</td></tr><tr><td class="confluenceTd"><p>DATALOADER_ZK_QUORUM</p></td><td class="confluenceTd"><p>List of Zookeeper nodes in comma separated format. This list must be the same as used in Zookeeper cluster configuration, (in the “zk.cfg” file).</p></td><td class="confluenceTd"><p>Must be specified</p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>DATALOADER_SERVICE_IP</p></td><td class="confluenceTd"><p>IP address the services will bind to (&quot;localhost&quot; cannot be used).</p></td><td class="confluenceTd"><p>Must be specified except for running standalone mode, and CLI is installed with service node</p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>EXECUTOR_TYPE</p></td><td class="confluenceTd"><p>Hadoop cluster version that DataLoader is running on. DataLoader supports Hadoop 1.0 (GPHD 1.2) and Hadoop 2.0(PHD 1.x) . Other distributions, including Apache, have not been not tested.</p></td><td class="confluenceTd"><p>mrv2</p></td><td class="confluenceTd"><p>mrv1/mrv2</p></td></tr><tr><td class="confluenceTd"><p>HADOOP_INSTALL</p></td><td class="confluenceTd"><p>The Hadoop installation directory. DataLoader uses it to set the classpath. Make sure this value is set correctly.</p></td><td class="confluenceTd"><p>${HADOOP_INSTALL} <br class="atl-forced-newline" /> If user does not export this shell env variable or value is empty, it must be specified manually <br class="atl-forced-newline" /><br class="atl-forced-newline" /></p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>HADOOP_CONF_DIR</p></td><td class="confluenceTd"><p>The Hadoop configuration directory. Set this value if you are using install_worker to install <br class="atl-forced-newline" /> workers. Otherwise, it is optional</p></td><td class="confluenceTd"><p>${HADOOP_CONF_DIR}</p><p>If user does not export this shell env variable or value is empty, it must be specified manually</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td colspan="1" class="confluenceTd">DATALOADER_METRICS_REPORTING</td><td colspan="1" class="confluenceTd">Whether metrics report should be enabled. If not enabled, progress information will not be available.</td><td colspan="1" class="confluenceTd">true</td><td colspan="1" class="confluenceTd">true, false</td></tr><tr><td class="confluenceTd"><p>DATALOADER_EXECUTOR_CAPACITY</p></td><td class="confluenceTd"><p>The total number of slots(MRv1) or containers (MRv2) that are available to DataLoader. This number, called “workers,” is set according to expected number of stream jobs, batch jobs, and capacity in the HDFS cluster. As an example, the number would be 20 on a 10 node Hadoop cluster to support up to 10 stream jobs, and leave capacity for copying 10s of TB of data in multiple simultaneous batch jobs. You must set this value for DataLoader to run correctly.</p></td><td class="confluenceTd"><p>No default value, must be specified except for standalone mode.</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td colspan="1" class="confluenceTd">DATALOADER_SYSTEM_DIR</td><td colspan="1" class="confluenceTd">This is a value pointer to a directory on the executor's corresponding HDFS. This folder is used by DataLoader as its working directory; it should be writable by the &quot;dataloader&quot; user; This folder should be created and grant edwrite access to the &quot;dataloader&quot; user attempting to start DataLoader service in distributed mode.</td><td colspan="1" class="confluenceTd">/datsadir/</td><td colspan="1" class="confluenceTd">N/A</td></tr><tr><td class="confluenceTd"><p>DATALOADER_DATA_DIR</p></td><td class="confluenceTd"><p>The location to put DataLoader data files.</p></td><td class="confluenceTd"><p>For RPM installation, it is set in /etc/default/dataloader, value is: /var/lib/gphd/dataloader. <br class="atl-forced-newline" /> In other case, it is ${DATALOADER_HOME}/data</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>DATALOADER_LOG_DIR</p></td><td class="confluenceTd"><p>The location to put the DataLoader log files.</p></td><td class="confluenceTd"><p>For RPM installation, it is set in /etc/default/dataloader, value is: /var/log/gphd/dataloader. <br class="atl-forced-newline" /> In other case, it is set to: ${DATALOADER_HOME}/log</p></td><td class="confluenceTd"><p> </p></td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">Do not modify the following parameters.</span></p><ul><li>DATALOADER_HOME</li><li>DATALOADER_CONF_DIR</li><li>ZK_RUNTIME_DIR</li><li>ENGINE_HOME</li></ul><p><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;"><br /><br /></span></p><p>Start and Stop DataLoader services</p><ol><li>Change file ownership for the Linux account login. Change the permission of the file /etc/shadow to be readable by the group root:<p> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">root# chmod g+r /etc/shadow
</pre>
</div></div></li></ol><h3 id="InstallingandConfiguringDataLoader-StartDataLoadermanagerdirectlyusingstartupscript">Start DataLoader manager directly using startup script</h3><ol><li><p>Login to the DataLoader master node as dladmin, and go to the /bin directory of the DataLoader installed location:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$su - dladmin
$cd /usr/local/gphd/dataloader-2.0.1/bin/
</pre>
</div></div><p>Note: to reset the default dlamin user password, login as root and use &quot;passwd dladmin&quot; to change password</p></li><li><p>To start DataLoader service:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$sudo -u dataloader ./dataloader.sh start
</pre>
</div></div><p>Note: To control DataLoader to start in pseudo/distributed mode, please change the &quot;DATALOADER_START_MODE&quot; property in the dataloader-env.sh file;</p></li><li><p>To stop DataLoader service:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$sudo -u dataloader ./dataloader.sh stop
</pre>
</div></div></li></ol><p>Note: In the above command, <em>dataloader</em> is a service the user created during installation.</p><h3 id="InstallingandConfiguringDataLoader-UsingtheLinuxserviceutilitytostart/stopDataLoaderservices">Using the Linux service utility to start/stop DataLoader services</h3><p>Users can also use the Linux service utility to start/stop DataLoader services. </p><p>1. To start DataLoader servcies:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ sudo service dataloader-manager start</pre>
</div></div><p>2. To stop DataLoader services:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ sudo service dataloader-manager stop</pre>
</div></div><p> </p><h3 id="InstallingandConfiguringDataLoader-AdvancedConfigurations"><span style="line-height: 1.4285715;"><br /> </span><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Advanced Configurations</span></h3><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">These configurations are used for performance tuning and are found in the /usr/local/gphd/dataloader-2.0.0/conf/dataloader.xml file.</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Parameter</p></th><th class="confluenceTh"><p>Explanation</p></th><th class="confluenceTh"><p>Default value</p></th><th class="confluenceTh"><p>Options</p></th></tr><tr><td class="confluenceTd"><p>dataloader.zk.address</p></td><td class="confluenceTd"><p>Comma separated host/port list of Zookeeper. This value should be be changed: please change the dataloader_ZK_QUORUM in the <em>dataloader-env.sh</em> file.</p></td><td class="confluenceTd"><p>${DATALOADER_ZK_QUORUM}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.manager.service.port</p></td><td class="confluenceTd"><p>The manager restful interface listening port;</p></td><td class="confluenceTd"><p>12380</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.monitoring.enable</p></td><td class="confluenceTd"><p>This flag specifies whether to enable the metrics reporting mechanism for DataLoader. Since progress monitoring depends on metrics reporting, disabling this parameter will also disable progress reporting.</p></td><td class="confluenceTd"><p>true</p></td><td class="confluenceTd"><p>true/false</p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.server.host</p></td><td class="confluenceTd"><p>rpc host address for metrics reporting server. This parameter should be set to manager's host.<br />This value should not be changed, if you want to change this value, please modify DATALOADER_SERVICE_IP in the dataloader-env.sh file.</p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.server.port</p></td><td class="confluenceTd"><p>rpc port for progress monitoring server</p></td><td class="confluenceTd"><p>12322</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.service.rest.port</p></td><td class="confluenceTd"><p>The scheduler restful interface listening port;</p></td><td class="confluenceTd"><p>12321</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.service.rest.host *</p></td><td class="confluenceTd"><p>The scheduler restful interface binding address. This value should not be changed, if you want to change this value, please change DATALOADER_SERVICE_IP in the dataloader-env.sh file. </p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.taskscheduler.host</p></td><td class="confluenceTd"><p>The scheduler's host, worker will use this to contact scheduler for runtime task scheduling, <br class="atl-forced-newline" /> This value should not be changed, if you want to change this value, please change DATALOADER_SERVICE_IP in the <em>dataloader-env.sh</em> file.</p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.taskscheduler.port</p></td><td class="confluenceTd"><p>The scheduler's port. The worker will use this to contact the scheduler for runtime task scheduling,</p></td><td class="confluenceTd"><p>12320</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td colspan="1" class="confluenceTd">dataloader.worker.reader.num</td><td colspan="1" class="confluenceTd"><p>The number of reader threads to be started in each worker. <br />Reader threads are responsible for reading data from data sources. Using multiple reader threads can enhance I/O read parallelism. However, adding excessive reader threads can burden system resources due to the context switch between reader threads.</p></td><td colspan="1" class="confluenceTd">3</td><td colspan="1" class="confluenceTd"> </td></tr><tr><td colspan="1" class="confluenceTd">dataloader.worker.writer-pipeline.num</td><td colspan="1" class="confluenceTd"><p>The number of writer/pipeline threads that will be started in each worker. <br />Writer threads are responsible for writing data to its destination. Using multiple writer threads can enhance I/O write parallelism. However, adding excessive writer threads can burden system resources due to the context switch between writer threads.</p></td><td colspan="1" class="confluenceTd">5</td><td colspan="1" class="confluenceTd"> </td></tr><tr><td class="confluenceTd"><p>dataloader.worker.buffer.num</p></td><td class="confluenceTd"><p>The number of buffers which could be used in each worker for batch jobs. <br />When all the buffers run out of DataLoader worker resources, the reader threads wait for buffers to become available, before reading next piece of data. <br />Increasing the number of memory buffers used by DataLoader workers can potentially enhance the throughput and latency of a worker assigned to a job’s workload. However, this strategy will use more system resources.</p></td><td class="confluenceTd"><p>12</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.worker.buffer.size</p></td><td class="confluenceTd"><p>The size of each buffer for batch job workers. <br />A reader thread first fetches a buffer of the specified size, before reading data from the source. It fills the buffer until either the buffer is full or the designated piece of data is completely read into buffer, then passwa it to the writer thread, to write it to the destination.<br />Increasing the size of the memory buffers used by DataLoader workers can potentially enhance IO throughput, since it allows data read to occur in batch mode, reducing the number of I/O operations. However, it will use more system resources.</p></td><td class="confluenceTd"><p>16 * 1024 * 1024 (16MB)</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td colspan="1" class="confluenceTd">dataloader.worker.streaming.server.memory.upper.limit</td><td colspan="1" class="confluenceTd"><p>The maxiumum memory that the worker can use to hold incloming data in pushstream jobs. <br />When the size of event data held in a worker's memory not written to its destination exceeds this memory limit, the worker will stop receiving event data from the client, to avoid memory leakage.<br />Increasing the value of this parameter can potentially enhance the latency of pushstream jobs when a worker is receiving large amounts of data from many clients. However, it will use more system resources.</p></td><td colspan="1" class="confluenceTd">335544320</td><td colspan="1" class="confluenceTd"> </td></tr><tr><td colspan="1" class="confluenceTd">dataloader.executor.notification.host</td><td colspan="1" class="confluenceTd"><p>The IP address on which the executor is to listen for the job status notification:<br />${DATALOADER_SERVICE_IP}</p></td><td colspan="1" class="confluenceTd"> </td><td colspan="1" class="confluenceTd"> </td></tr><tr><td colspan="1" class="confluenceTd">dataloader.executor.notification.port</td><td colspan="1" class="confluenceTd">The port on which the executor is to listen for job status notifications: 12324</td><td colspan="1" class="confluenceTd">12324</td><td colspan="1" class="confluenceTd"> </td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> Advanced features are used primarily for performance tuning.</span></p><p><span style="line-height: 1.4285715;"> </span><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configure DataLoader CLI</span></p><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">To use the DataLoader CLI for managing jobs and datastores, it must be configured.</span></p><p>The configuration file for CLI is located at:</p><pre>${DATALOADER_HOME}/conf/dataloader-cli.conf.</pre><p>It is a text file with key/value pair content.</p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>name</p></th><th class="confluenceTh"><p>default value</p></th><th class="confluenceTh"><p>description</p></th></tr><tr><td class="confluenceTd"><p>dataloader.api.url</p></td><td class="confluenceTd"><p><a href="http://localhost:12380/manager" class="external-link" rel="nofollow">http://localhost:12380/manager</a></p></td><td class="confluenceTd"><p>This is the location of the DataLoader scheduler's restful interface address. If CLI is installed on the same machine as the DataLoader service package, this value doesn't need to be changed.</p></td></tr><tr><td class="confluenceTd"><p>dataloader.zk.address</p></td><td class="confluenceTd"><p><a href="http://localhost:12181" class="external-link" rel="nofollow">localhost:12181</a></p></td><td class="confluenceTd"><p>This is the location of the Zookeeper servers, provided as a comma-separated list (<span>for example: </span><em><a href="http://host1:2181%2Chost2:2181" class="external-link" rel="nofollow">host1:2181,host2:2181</a>)</em>. This list should be the same as used in dataloader-env.sh earlier. Do not change if using standalone or pseudo-distributed modes, as the embedded-zookeeper address is the default.</p></td></tr><tr><td class="confluenceTd"><p>dataloader.cli.queue.max.buffer</p></td><td class="confluenceTd"><p>32768</p></td><td class="confluenceTd"><p>The maximum number of unacknowledged messages that the client can hold in memory. Will be overwritten at run time if the command line param --queue-size is specified.<br />To avoid memory leakage, when the number of unacknowledged events/messages held in the client's memory exceeds the specified limits, the client will stop accepting events from the stream until the resource become available. <br />Increasing the value of this parameter can potentially enhance the latency when a client is receiving numerous events. However, this will use more system resources.</p></td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">If using pseudo-distributed mode,you can use default values, provided you are not using an external Zookeeper.</span></p><p><span style="line-height: 1.4285715;"><br /></span></p>
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" style="background: url(http://confluence.greenplum.com/images/border/border_bottom.gif) repeat-x;">
                <p><small>Document generated by Confluence on Sep 23, 2013 15:58</small></p>
            </div>
        </div>     </body>
</html>
