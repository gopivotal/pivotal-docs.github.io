<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
    <head>
        <title>Hadoop : DataLoader Copy Strategy and Transfer Policy</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body>
        <div id="page">
            <div id="main">
                <div id="main-header" class="pageSectionHeader">
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Hadoop : DataLoader Copy Strategy and Transfer Policy
                        </span>
                    </h1>

                    <div class="page-metadata">
                        <p>This page last changed on Aug 22, 2013 by <font color="#0050B2">beckmj</font>.</p>
                    </div>
                </div>

                <div id="content" class="view">
                    <div id="main-content" class="wiki-content group">
                    <p>When loading from different data sources, the user must define the job spec, copy strategy, and transfer policy before submitting a job for Data Loader to run. </p><p>Copy Strategy defines the loading job scheduling strategy. Different copy strategies are used depending on the loading requirements. There could be more than one strategies applicable to a loading scenario. In general, there are 2 categories of strategies corresponding to batch and streaming jobs respectively:</p><ol><li>Batch Job: Uniform, Locality, LocalFS, Dynamic</li><li>Streaming Job: Push streaming</li></ol><p>A Job Specification File (also known as a Transfer Spec or JobSpec) is an XML-based file that defines the job being submitted. The Job Specification section provides information on contents of these files and gives examples. If jobs are submitted through the UI forms, you simply select appropriate entries. </p><h1 id="DataLoaderCopyStrategyandTransferPolicy-CopyStrategy">Copy Strategy</h1><p>DataLoader supports 6 copy strategies, shown in the table below.</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Strategy Name Supported Target</p></th><th class="confluenceTh"><span style="color: rgb(0,0,0);">Description </span></th><th class="confluenceTh"><span style="color: rgb(0,0,0);">Supported Source </span></th><th class="confluenceTh"><span style="color: rgb(0,0,0);">Supported Target</span></th></tr><tr><td class="confluenceTd">locality</td><td class="confluenceTd"><p>Locality Copy Strategy exploits the location information from the data source, such that the job splits created by Job Planner will be assigned to workers having the highest possibility being co-located with the data blocks, thus reducing inter-machine traffic. Locality will be achieved during reads when DataLoader is deployed on source HDFS cluster, and during writes when deployed on destination HDFS cluster.</p></td><td class="confluenceTd">HDFS</td><td class="confluenceTd">HDFS/HDFS2 supports concat*</td></tr><tr><td class="confluenceTd">localfs</td><td class="confluenceTd"><p>LocalFS strategy is a special case of Locality strategy where source data is on the local disks of the DataLoader worker nodes. The location information must be used to verify that the workers are copying from the disk mounted on the same server, as the local file system can not be accessed from a remote machine via DataLoader. LocalFS strategy tells the DataLoader scheduler to assign the file splits only to the host where the files are stored. <br />LocalFS strategy supports additional optimization on top of host level assignment. In transfer specification files, users can identify the disk where the files are stored, and can specify the number of worker processes to copy from one disk. DataLoader scheduler will schedule the specified number of worker processes per disk to maximize usage of the available disk bandwidth available. <br />Localfs strategy is NOT supported with YARN/MapReduce2</p></td><td class="confluenceTd">Raw file system</td><td class="confluenceTd"><span>HDFS, HDFS2</span></td></tr><tr><td class="confluenceTd">uniform</td><td class="confluenceTd">Uniform strategy uniformly assigns loading tasks to all the loader machines according to file size.</td><td class="confluenceTd">FTP, NFS</td><td class="confluenceTd"><span>HDFS, HDFS2</span></td></tr><tr><td class="confluenceTd">dynamic</td><td class="confluenceTd"><p>Dynamic strategy is a batch copy strategy where the copy tasks are assigned on demand rather than pre-allocated in batch mode, i.e., rather than generating the job spits beforehand, the copy tasks are pooled and allocated to workers at run time. This strategy is used when a large number of small files must be copied.</p><p>In a heterogeneous environment, it is easy to see long tail effects if the tasks are assigned more or less uniformly. The benefits of using dynamic strategy is that, the workers will be kept busy as long as there are still tasks to work on, whereas if a static allocation is used, some workers will finish and exit early and leave the stragglers running till complete. The downside of using dynamic strategy is, when there are large volume of data needs to be copied, usually the number of workers will scale up, and they will compete for the tasks to run, which inevitably causes contention and eventually hurts scalability.</p></td><td class="confluenceTd">NFS, FTP, HDFS, HDFS2 </td><td class="confluenceTd"><span>HDFS, HDFS2</span></td></tr><tr><td class="confluenceTd">connection limited</td><td class="confluenceTd">This limits the connections to data sources by the specified number of workers. This strategy is used when users are loading from FTP, or other data sources where the connections need to be throttled per the configured server capacity. </td><td class="confluenceTd">FTP</td><td class="confluenceTd"><span>HDFS, HDFS2</span></td></tr><tr><td colspan="1" class="confluenceTd">pushstream</td><td colspan="1" class="confluenceTd">Pushstream copy strategy is used when a user submits a pushstream job. This strategy will allow the user to specify the number of workers to support the client it is connecting to. Similar to pull streaming job, Data Loader scheduler will over provision the number of required workers to support the job to make sure the low latency scheduling can be achieved. </td><td colspan="1" class="confluenceTd">n/a</td><td colspan="1" class="confluenceTd"><span>HDFS, HDFS2</span></td></tr><tr><td colspan="1" class="confluenceTd">intelligent</td><td colspan="1" class="confluenceTd"><p>With this strategy, DataLoader will automatically pick the suitable copy strategy for the user scenario. For example, if copying from HDFS, and target HDFS supports concat, then locality strategy will be<br />selected; if copied from local file system, localfs strategy will be selected; otherwise uniform strategy will be used.</p></td><td colspan="1" class="confluenceTd">All file sources</td><td colspan="1" class="confluenceTd"><span>HDFS, HDFS2</span></td></tr></tbody></table></div><p><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Intelligent Copy</span></p><p>In Intelligent Copy, the DataLoader determines the best strategy based on the source and target data store configuration.</p><p>The table below shows how the strategy is selected.</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh">Sourcre Datastore</th><th class="confluenceTh">Desitnation Datastore</th><th class="confluenceTh">Intelligent Approach</th></tr><tr><td class="confluenceTd">HDFS</td><td class="confluenceTd"><p>HDFS with concat support</p></td><td class="confluenceTd">locality strategy</td></tr><tr><td class="confluenceTd">HDFS</td><td class="confluenceTd"><p>HDFS without concat support</p></td><td class="confluenceTd">uniform stragegy</td></tr><tr><td class="confluenceTd">Local FS</td><td class="confluenceTd"><p>HDFS with concat support</p></td><td class="confluenceTd">localfs with chunking</td></tr><tr><td class="confluenceTd">Local FS</td><td class="confluenceTd"><p>HDFS without concat support</p></td><td class="confluenceTd">localfs</td></tr><tr><td colspan="1" class="confluenceTd">NFS</td><td colspan="1" class="confluenceTd"><p>HDFS with concat support</p></td><td colspan="1" class="confluenceTd">uniform strategy with chunking</td></tr><tr><td colspan="1" class="confluenceTd">NFS</td><td colspan="1" class="confluenceTd"><p>HDFS without concat support</p></td><td colspan="1" class="confluenceTd">uniform strategy</td></tr><tr><td colspan="1" class="confluenceTd">FTP</td><td colspan="1" class="confluenceTd">\</td><td colspan="1" class="confluenceTd">uniform strategy</td></tr></tbody></table></div><p><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Supported Copy/Transfer Combinations</span></p><p>The tables below show the supported combinations of copy strategies and transfer policies for the different types of data stores.</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Source Data Store Type</p></th><th class="confluenceTh"><p>Supported Copy Strategy</p></th><th class="confluenceTh"><p>Supported Policy</p></th><th class="confluenceTh"><p>File Transfer Spec</p></th></tr><tr><td class="confluenceTd"><p>HDFS</p></td><td class="confluenceTd"><p>locality  <br class="atl-forced-newline" /> uniform <br class="atl-forced-newline" /> dynamic <br class="atl-forced-newline" /> intelligent*</p></td><td class="confluenceTd"><p>Chunking (If destination data store support concat) <br class="atl-forced-newline" /> Bandwidth-throttling <br class="atl-forced-newline" /> Overwrite <br class="atl-forced-newline" /> worker-number  <br class="atl-forced-newline" /> Compression (chunking needs to be disabled)</p></td><td class="confluenceTd"><p>folder <br class="atl-forced-newline" /> file <br class="atl-forced-newline" /> glob <br class="atl-forced-newline" /> list</p></td></tr><tr><td class="confluenceTd"><p>NFS</p></td><td class="confluenceTd"><p>uniform <br class="atl-forced-newline" /> dynamic <br class="atl-forced-newline" /> intelligent*</p></td><td class="confluenceTd"><p>Chunking (if destination cluster support concat) <br class="atl-forced-newline" /> Bandwidth-throttling <br class="atl-forced-newline" /> Overwrite <br class="atl-forced-newline" /> worker-number <br class="atl-forced-newline" /> Compression (chunking needs to be disabled)</p></td><td class="confluenceTd"><p>folder <br class="atl-forced-newline" /> file <br class="atl-forced-newline" /> glob <br class="atl-forced-newline" /> list</p></td></tr><tr><td class="confluenceTd"><p>LocalFS</p></td><td class="confluenceTd"><p>localfs <br class="atl-forced-newline" /> intelligent*</p></td><td class="confluenceTd"><p>Chunking <br class="atl-forced-newline" /> Bandwidth-throttling <br class="atl-forced-newline" /> Overwrite <br class="atl-forced-newline" /><span style="color: rgb(0,0,0);">worker-number</span><br class="atl-forced-newline" /><span style="color: rgb(0,0,0);">worker-per-disk</span><br class="atl-forced-newline" /> Compression (chunking needs to be disabled)</p></td><td class="confluenceTd"><p>folder <br class="atl-forced-newline" /> file <br class="atl-forced-newline" /> glob <br class="atl-forced-newline" /> list</p></td></tr><tr><td class="confluenceTd"><p>FTP</p></td><td class="confluenceTd"><p>uniform <br class="atl-forced-newline" /> connection limited <br class="atl-forced-newline" /> dynamic <br class="atl-forced-newline" /> intelligent*</p></td><td class="confluenceTd"><p>Bandwidth-throttling <br class="atl-forced-newline" /> Overwrite <br class="atl-forced-newline" /> worker-number  <br class="atl-forced-newline" /> Compression (chunking needs to be disabled) </p></td><td class="confluenceTd"><p>folder <br class="atl-forced-newline" /> file <br class="atl-forced-newline" /> glob <br class="atl-forced-newline" /> list</p></td></tr></tbody></table></div><p>Note: by using <em>intelligent</em> strategy, Dataloader will choose the appropriate strategy for performing the copy.</p><h2 id="DataLoaderCopyStrategyandTransferPolicy-ThecombinationforPushStreamjobs">The combination for Push Stream jobs </h2><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Source Data Store Type</p></th><th class="confluenceTh"><p>Copy Strategy</p></th><th class="confluenceTh"><p>Policy</p></th><th class="confluenceTh"><p>File Transfer Spec</p></th></tr><tr><td class="confluenceTd"><p>N/A <br class="atl-forced-newline" />For push stream scenarios, DataLloader accepts events and/or messages msgs from any active client.</p></td><td class="confluenceTd"><p>pushstream intelligent*</p></td><td class="confluenceTd"><p>worker-number <br class="atl-forced-newline" />Compression Bandwidth-throttling <br class="atl-forced-newline" /><br class="atl-forced-newline" /><br class="atl-forced-newline" /></p></td><td class="confluenceTd"><p>The Job Specification/Transfer spec must specify the root path in the destination fs. <br class="atl-forced-newline" /><br class="atl-forced-newline" />All msgs/events DataLoader has received will be serialized in files <br class="atl-forced-newline" />under that root path following certain naming conventions.</p></td></tr></tbody></table></div>
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" style="background: url(http://confluence.greenplum.com/images/border/border_bottom.gif) repeat-x;">
                <p><small>Document generated by Confluence on Sep 23, 2013 15:58</small></p>
            </div>
        </div>     </body>
</html>
